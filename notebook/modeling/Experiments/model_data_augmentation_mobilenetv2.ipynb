{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pandas\n",
    "# %pip install scikit-learn\n",
    "# %pip install plotly\n",
    "# %pip install numpy\n",
    "# %pip install matplotlib\n",
    "# %pip install nbformat\n",
    "# %pip install opencv-python\n",
    "# %pip install tensorflow\n",
    "# %pip install wandb\n",
    "# %pip install imblearn\n",
    "# %pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import os\n",
    "import plotly.express as px\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import wandb\n",
    "%env \"WANDB_NOTEBOOK_NAME\" \"model_data_augmentation_mobilenetv2.ipynb\"\n",
    "\n",
    "wandb.login()\n",
    "\n",
    "from wandb.integration.keras import WandbMetricsLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df = pd.read_csv(\n",
    "    \"../../../data/processed/combined/combined_label.csv\", index_col=False\n",
    ")\n",
    "data_dir = \"../../../data/processed/combined/img/\"\n",
    "\n",
    "label_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dir_path, img_size):\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for index, row in label_df.iterrows():\n",
    "        image_path = os.path.join(dir_path, row[\"image_name\"])\n",
    "        img = cv2.imread(image_path)\n",
    "        img = cv2.resize(img, img_size, interpolation=cv2.INTER_AREA).astype(\"float32\")\n",
    "\n",
    "        X.append(img)\n",
    "        y.append(row[\"expression_label\"])\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (96, 96)\n",
    "\n",
    "X, y = load_data(data_dir, IMG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = pd.get_dummies(label_df[\"expression_label\"])\n",
    "dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dummies.values\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.80\n",
    "test_ratio = 0.10\n",
    "validation_ratio = 0.10\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_ratio)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train, y_train, test_size=validation_ratio / (train_ratio + test_ratio)\n",
    ")\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_valid.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribution of classes in each set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"angry\", \"disgust\", \"fear\", \"happy\", \"neutral\", \"sad\", \"surprise\"]\n",
    "class_count_in_train_set = np.sum(y_train, axis=0)\n",
    "\n",
    "fig = px.bar(x=labels, y=class_count_in_train_set, color=labels)\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Distribution of each label in train set\",\n",
    "    xaxis_title=\"Expressions\",\n",
    "    yaxis_title=\"Count\",\n",
    "    height=600,\n",
    "    width=800,\n",
    ")\n",
    "\n",
    "fig.update_traces(texttemplate=\"%{y}\", textposition=\"inside\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_count_in_validation_set = np.sum(y_valid, axis=0)\n",
    "fig = px.bar(x=labels, y=class_count_in_validation_set, color=labels)\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Distribution of each label in validation set\",\n",
    "    xaxis_title=\"Expressions\",\n",
    "    yaxis_title=\"Count\",\n",
    "    height=600,\n",
    "    width=800,\n",
    ")\n",
    "\n",
    "fig.update_traces(texttemplate=\"%{y}\", textposition=\"inside\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_count_in_test_set = np.sum(y_test, axis=0)\n",
    "fig = px.bar(x=labels, y=class_count_in_test_set, color=labels)\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Distribution of each label in test set\",\n",
    "    xaxis_title=\"Expressions\",\n",
    "    yaxis_title=\"Count\",\n",
    "    height=600,\n",
    "    width=800,\n",
    ")\n",
    "\n",
    "fig.update_traces(texttemplate=\"%{y}\", textposition=\"inside\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oversampling with SMOTE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all dimensions of the resulting X\n",
    "n_samples, height, width, n_channels = [X_train.shape[index] for index in range(4)]\n",
    "\n",
    "# reshape X because SMOTE accepts only (n_samples, n_channels*height*weight)-type data\n",
    "X_train_reshaped = X_train.reshape(n_samples, n_channels * height * width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the SMOTE model\n",
    "smote = SMOTE(random_state=62)\n",
    "\n",
    "# perform re-sampling on modified X given y\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train_reshaped, y_train)\n",
    "X_train_smote = X_train_smote.reshape(len(X_train_smote), 96, 96, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_count_in_train_smote_set = np.sum(y_train_smote, axis=0)\n",
    "fig = px.bar(x=labels, y=class_count_in_train_smote_set, color=labels)\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Distribution of each label in train set after SMOTE\",\n",
    "    xaxis_title=\"Expressions\",\n",
    "    yaxis_title=\"Count\",\n",
    "    height=600,\n",
    "    width=800,\n",
    ")\n",
    "\n",
    "fig.update_traces(texttemplate=\"%{y}\", textposition=\"inside\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training with data augmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = MobileNetV2(\n",
    "    weights=\"imagenet\", include_top=False, input_shape=IMG_SIZE + (3,)\n",
    ")\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 7\n",
    "\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation=\"relu\"))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(NUM_CLASSES, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"Emotion Recognition\",\n",
    "    name=\"mobileNetV2_with_data_augmentation_epoch30_10_batch64\",\n",
    "    # track hyperparameters and run metadata with wandb.config\n",
    "    config={\n",
    "        \"architecture\": \"MobileNetV2\",\n",
    "        \"optimizer_1\": \"adam\",\n",
    "        \"optimizer_2\": \"Adam(learning_rate=1e-5)\",\n",
    "        \"loss\": \"categorical_crossentropy\",\n",
    "        \"metric\": [\"categorical_accuracy\"],\n",
    "        \"epoch_frozen\": 30,\n",
    "        \"epoch_unfrozen\": 10,\n",
    "        \"batch_size\": 64,\n",
    "        \"IMG_SIZE\": \"96, 96\",\n",
    "        \"Dense_1\": 512,\n",
    "        \"Dense_1_activation\": \"relu\",\n",
    "        \"Dropout\": 0.2,\n",
    "        \"Dense_2\": 7,\n",
    "        \"Dense_2_activation\": \"softmax\",\n",
    "    },\n",
    ")\n",
    "\n",
    "config = wandb.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augment and normalize/standardize for training set\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=(0.8, 1.2),\n",
    "    zoom_range=0.1,\n",
    "    samplewise_center=True,\n",
    "    samplewise_std_normalization=True,\n",
    ")\n",
    "\n",
    "# only normalize/standardize for validation and test set\n",
    "test_val_datagen = ImageDataGenerator(\n",
    "    samplewise_center=True,\n",
    "    samplewise_std_normalization=True,\n",
    ")\n",
    "\n",
    "\n",
    "# get batch iterator for training\n",
    "train_iterator = train_datagen.flow(\n",
    "    X_train_smote, y_train_smote, batch_size=config[\"batch_size\"]\n",
    ")\n",
    "# get batch iterator for validation\n",
    "val_iterator = test_val_datagen.flow(X_valid, y_valid, batch_size=config[\"batch_size\"])\n",
    "\n",
    "# get batch iterator for test (use only once for evaluation)\n",
    "test_iterator = test_val_datagen.flow(X_test, y_test, batch_size=config[\"batch_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=config[\"loss\"],\n",
    "    optimizer=config[\"optimizer\"],\n",
    "    metrics=config[\"metric\"],\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_iterator,\n",
    "    validation_data=val_iterator,\n",
    "    epochs=config[\"epoch_frozen\"],\n",
    "    callbacks=[WandbMetricsLogger(log_freq=5)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = True\n",
    "\n",
    "model.compile(\n",
    "    loss=config[\"loss\"],\n",
    "    optimizer=Adam(learning_rate=1e-5),\n",
    "    metrics=config[\"metric\"],\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_iterator,\n",
    "    validation_data=val_iterator,\n",
    "    epochs=config[\"epoch_unfrozen\"],\n",
    "    callbacks=[WandbMetricsLogger(log_freq=5)],\n",
    ")\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"../../../model/240606_mobilenetv2_augmentation_model.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion matrix with validation set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def samplewise_standardization(X):\n",
    "    return (X - np.mean(X)) / np.std(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid_normalized = samplewise_standardization(X_valid)\n",
    "\n",
    "y_pred = model.predict(X_valid_normalized)\n",
    "true_class = tf.argmax(y_valid, 1)\n",
    "predicted_class = tf.argmax(y_pred, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(true_class, predicted_class)\n",
    "\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(cm, annot=True, fmt=\"g\", ax=ax)\n",
    "\n",
    "# labels, title and ticks\n",
    "\n",
    "ax.set_xlabel(\"Predicted labels\")\n",
    "ax.set_ylabel(\"True labels\")\n",
    "ax.set_title(\"Confusion Matrix\")\n",
    "\n",
    "ax.xaxis.set_ticklabels(\n",
    "    [\"angry\", \"disgust\", \"fear\", \"happy\", \"neutral\", \"sad\", \"surprise\"]\n",
    ")\n",
    "\n",
    "ax.yaxis.set_ticklabels(\n",
    "    [\"angry\", \"disgust\", \"fear\", \"happy\", \"neutral\", \"sad\", \"surprise\"]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
